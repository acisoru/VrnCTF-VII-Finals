#!/bin/bash
set -e

# Default values
TEAM_ID=${1:-1}
WEB_PORT=$((30000 + $TEAM_ID)) # Using valid NodePort range (30000-32767)
K3S_PORT=$((6443 + $TEAM_ID))
CONTAINER_NAME="k3s-ctf-team${TEAM_ID}"

echo "[+] Setting up team $TEAM_ID instance..."
echo "[+] Web port: $WEB_PORT"
echo "[+] K3s port: $K3S_PORT"

# Check if template exists
if ! lxc info k3s-ctf-template &>/dev/null; then
    echo "[!] Template container not found. Please run create-template.sh first."
    exit 1
fi

# Check if team container already exists and delete it if it does
if lxc info $CONTAINER_NAME &>/dev/null; then
    echo "[+] Team container already exists, removing it..."
    lxc stop $CONTAINER_NAME --force || true
    lxc delete $CONTAINER_NAME || true
fi


echo "[+] Creating team container from template..."
lxc copy k3s-ctf-template/template $CONTAINER_NAME

# Again, if I see security.privileged=true here, I'll personally murder you
echo "[+] Configuring container security settings..."
lxc config set $CONTAINER_NAME security.nesting=true security.syscalls.intercept.mknod=true security.syscalls.intercept.setxattr=true

echo "[+] Starting team container..."
lxc start $CONTAINER_NAME

echo "[+] Waiting for container to be ready..."
sleep 10

echo "[+] Configuring K3s to use team-specific port..."
lxc exec $CONTAINER_NAME -- bash -c "sed -i 's/6443/${K3S_PORT}/g' /etc/systemd/system/k3s.service"

echo "[+] Updating hostname in K3s config..."
lxc exec $CONTAINER_NAME -- bash -c "sed -i 's/k3s-ctf-template/${CONTAINER_NAME}/g' /etc/rancher/k3s/k3s.yaml || true"

echo "[+] Starting K3s..."
lxc exec $CONTAINER_NAME -- systemctl daemon-reload
lxc exec $CONTAINER_NAME -- systemctl restart k3s

echo "[+] Waiting for K3s to be ready..."
sleep 30

# Configure CoreDNS to use 1.1.1.1 because I LOVE having half of internet blocked
echo "[+] Configuring CoreDNS to use 1.1.1.1..."
lxc exec $CONTAINER_NAME -- bash -c "kubectl get configmap -n kube-system coredns -o yaml > /tmp/coredns-cm.yaml"
lxc exec $CONTAINER_NAME -- bash -c "cat > /tmp/coredns-patch.yaml << EOF
data:
  Corefile: |
    .:53 {
        errors
        health
        ready
        kubernetes cluster.local in-addr.arpa ip6.arpa {
            pods insecure
            fallthrough in-addr.arpa ip6.arpa
        }
        hosts /etc/coredns/NodeHosts {
            ttl 60
            reload 15s
            fallthrough
        }
        prometheus :9153
        forward . 1.1.1.1
        cache 30
        loop
        reload
        loadbalance
        import /etc/coredns/custom/*.override
    }
    import /etc/coredns/custom/*.server
EOF"
lxc exec $CONTAINER_NAME -- bash -c "kubectl patch configmap/coredns -n kube-system --patch \"\$(cat /tmp/coredns-patch.yaml)\""
lxc exec $CONTAINER_NAME -- bash -c "kubectl rollout restart deployment coredns -n kube-system"
lxc exec $CONTAINER_NAME -- bash -c "rm /tmp/coredns-patch.yaml"


echo "[+] Verifying node setup..."
lxc exec $CONTAINER_NAME -- kubectl get nodes -o wide
NODE_COUNT=$(lxc exec $CONTAINER_NAME -- kubectl get nodes --no-headers | wc -l)
if [ "$NODE_COUNT" -ne 1 ]; then
    echo "[!] Warning: Found $NODE_COUNT nodes instead of 1. If there's only 2 (box+template), that's expected. Else Ctrl+C and redeploy."
fi
lxc exec $CONTAINER_NAME -- sh -c "kubectl delete node k3s-ctf-template || true"

# Copy the kubeconfig from the container
echo "[+] Copying kubeconfig from the container..."
mkdir -p ~/.kube
lxc exec $CONTAINER_NAME -- cat /etc/rancher/k3s/k3s.yaml > ~/.kube/config.team${TEAM_ID}
sed -i "s/6443/${K3S_PORT}/g" ~/.kube/config.team${TEAM_ID}
export KUBECONFIG=~/.kube/config.team${TEAM_ID}

echo "[+] Using pre-built challenge files from template..."

# Modify the health check service deployment to use the team-specific port
echo "[+] Updating health check service configuration for team-specific ports..."
lxc exec $CONTAINER_NAME -- bash -c "sed -i 's/targetPort: 8080/targetPort: 8080\\n    nodePort: ${WEB_PORT}/g' /root/ctf-challenge/k8s/health-check-deployment.yaml"
lxc exec $CONTAINER_NAME -- bash -c "sed -i 's/type: ClusterIP/type: NodePort/g' /root/ctf-challenge/k8s/health-check-deployment.yaml"


echo "[+] Deploying the health check service..."
# Apply RBAC and deployment
lxc exec $CONTAINER_NAME -- kubectl apply -f /root/ctf-challenge/k8s/rbac.yaml
lxc exec $CONTAINER_NAME -- kubectl apply -f /root/ctf-challenge/k8s/health-check-deployment.yaml

# ->>> FLAG HERE <<<-
echo "[+] Creating the flag..."
FLAG=${FLAG:-"vrnctf{s0me0n3_f0rg0r_to_set_fl4g}"}

echo "$FLAG" > /tmp/flag.txt
chmod 600 /tmp/flag.txt
lxc file push /tmp/flag.txt $CONTAINER_NAME/root/flag.txt
lxc exec $CONTAINER_NAME -- chown root:root /root/flag.txt
lxc exec $CONTAINER_NAME -- chmod 600 /root/flag.txt

echo "[+] Waiting for deployment to be ready..."
lxc exec $CONTAINER_NAME -- kubectl wait --for=condition=available --timeout=300s deployment/health-check-service

# Forward ports
echo "[+] Setting up port forwarding..."
lxc config device add $CONTAINER_NAME k3s-api proxy listen=tcp:0.0.0.0:${K3S_PORT} connect=tcp:127.0.0.1:${K3S_PORT}
lxc config device add $CONTAINER_NAME web-port proxy listen=tcp:0.0.0.0:${WEB_PORT} connect=tcp:127.0.0.1:${WEB_PORT}

echo "[+] Setup complete!"
echo "[+] Challenge for Team ${TEAM_ID} is running at http://127.0.0.1:${WEB_PORT}"
echo "[+] Kubernetes API is available at https://127.0.0.1:${K3S_PORT}"
echo "[+] Flag is located at /flag.txt in the LXC container"
echo "[+] Kubeconfig is available at ~/.kube/config.team${TEAM_ID}"
echo "[+] To use kubectl with this instance, run: export KUBECONFIG=~/.kube/config.team${TEAM_ID}"
